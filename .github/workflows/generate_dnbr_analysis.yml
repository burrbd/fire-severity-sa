name: ðŸ”¥ Manual - Generate dNBR Analysis

on:
  workflow_dispatch:
    inputs:
      fire_id:
        description: 'Fire ID to process'
        required: true
        default: 'fire_001'
      force_reprocess:
        description: 'Force reprocessing even if exists'
        required: false
        default: false
        type: boolean

jobs:
  generate-dnbr-analysis:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Need full history for commit hash
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Generate dNBR analysis
      id: generate
      run: |
        # Get generator type from GitHub variables
        GENERATOR_TYPE="${{ vars.DNBR_GENERATOR_TYPE || 'dummy' }}"
        
        # Generate dNBR analysis and capture analysis ID
        analysis_id=$(python scripts/generate_dnbr_analysis.py data/fire.geojson $GENERATOR_TYPE | grep "Analysis ID:" | cut -d' ' -f3)
        
        # Output analysis ID for next action
        echo "analysis_id=$analysis_id" >> $GITHUB_OUTPUT
        echo "generator_type=$GENERATOR_TYPE" >> $GITHUB_OUTPUT
        
        echo "âœ… dNBR analysis generated: $analysis_id"
        echo "ðŸ”§ Generator type: $GENERATOR_TYPE"
        echo "ðŸ“‹ Using GitHub Variable: DNBR_GENERATOR_TYPE=$GENERATOR_TYPE"
        
    - name: Show analysis summary
      run: |
        echo "ðŸŽ¯ dNBR Analysis Summary:"
        echo "   Fire ID: ${{ github.event.inputs.fire_id }}"
        echo "   Force reprocess: ${{ github.event.inputs.force_reprocess }}"
        echo "   Analysis ID: ${{ steps.generate.outputs.analysis_id }}"
        echo "   Generator type: ${{ steps.generate.outputs.generator_type }}"
        echo ""
        echo "ðŸ“‹ Next steps:"
        echo "   1. Run 'Download dNBR Data' workflow with analysis ID: ${{ steps.generate.outputs.analysis_id }}"
        echo "   2. This will download the data and regenerate the map" 